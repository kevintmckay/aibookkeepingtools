name: daily-content

on:
  schedule:
    # 01:00 PM US/Pacific ≈ 21:00 UTC
    - cron: "0 21 * * *"
  workflow_dispatch: {}

permissions:
  contents: write

concurrency:
  group: daily-content
  cancel-in-progress: false

jobs:
  generate:
    runs-on: ubuntu-latest
    timeout-minutes: 45  # Increased from 30 to account for longer wait times

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Generate posts (with retries)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          POSTS_PER_RUN: "2"
          MODEL_OUTLINE: "gpt-5-mini"
          MODEL_DRAFT: "gpt-5-mini"     # flip to "gpt-5" if you have access
          DISABLE_HEARTBEAT: "1"        # skip heartbeat files in CI
        run: |
          set -euo pipefail
          attempts=0
          until ./scripts/generate_posts.py; do
            code=$?
            attempts=$((attempts+1))
            if [ $attempts -ge 5 ]; then
              echo "generator failed after $attempts attempts (exit $code)"
              exit $code
            fi
            sleep $(( attempts * 10 ))   # 10s, 20s, 30s, ...
          done

      - name: Commit & rebase-push new posts
        id: commit
        run: |
          set -euo pipefail

          git config user.name  "Content Bot"
          git config user.email "bot@users.noreply.github.com"

          # Stage ALL changes (posts + topics files, etc.)
          git add -A

          if git diff --cached --quiet; then
            echo "No changes to commit."
            echo "changed=0" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          git commit -m "chore: daily AI posts"

          # Fold in any files that changed between add & commit
          git add -A
          if ! git diff --cached --quiet; then
            git commit --amend --no-edit
          fi

          # Ensure clean tree before rebase
          git clean -fd

          git fetch origin main
          if ! git rebase origin/main; then
            echo "Rebase conflict. Aborting rebase."
            git rebase --abort || true
            exit 1
          fi

          # Push (retry once)
          tries=0
          until git push origin HEAD:main; do
            tries=$((tries+1))
            if [ $tries -ge 2 ]; then
              echo "Push still failing after rebase and retry."
              exit 1
            fi
            echo "Push race detected, refetching and rebasing then retrying..."
            git fetch origin main
            git rebase origin/main || { git rebase --abort || true; exit 1; }
            sleep 3
          done

          echo "changed=1" >> "$GITHUB_OUTPUT"

      - name: Collect URLs to verify
        id: urls
        if: steps.commit.outputs.changed == '1'
        run: |
          set -euo pipefail

          TMPDIR="$(mktemp -d)"
          CHANGED="$TMPDIR/changed_files.txt"
          URLS="$TMPDIR/urls.txt"
          BASE_URL="https://aibookkeepingtools.com"

          # Capture changed post files from the last commit
          { git log -1 --name-only --pretty="" | grep -E '^content/posts/.*\.md$' || true; } > "$CHANGED"

          # Build full URLs for sitemap check
          : > "$URLS"
          while read -r f; do
            [ -z "${f:-}" ] && continue
            slug="$(basename "$f" .md)"
            echo "${BASE_URL}/posts/${slug}/" >> "$URLS"
          done < "$CHANGED"

          echo "URLs to verify:"
          cat "$URLS" || true

          if [ -s "$URLS" ]; then
            echo "have_urls=1" >> "$GITHUB_OUTPUT"
            echo "urls_file=$URLS" >> "$GITHUB_OUTPUT"
          else
            echo "have_urls=0" >> "$GITHUB_OUTPUT"
          fi

      - name: Wait for Cloudflare Pages deployment and verify sitemap
        if: steps.urls.outputs.have_urls == '1'
        run: |
          set -euo pipefail
          BASE_URL="https://aibookkeepingtools.com"
          SITEMAP="${BASE_URL}/sitemap.xml"

          urls_file="${{ steps.urls.outputs.urls_file }}"

          echo "Waiting for Cloudflare Pages to build and deploy..."
          echo "This typically takes 3-5 minutes for Hugo sites on Cloudflare Pages"
          
          # Initial wait to let Cloudflare Pages start building
          sleep 120  # 2 minutes initial wait
          
          tries=0
          max=12     # Reduced attempts but longer intervals
          ok=0
          
          while [ $tries -lt $max ]; do
            tries=$((tries+1))
            echo "Fetching sitemap (attempt $tries/$max): $SITEMAP"
            
            map="$(curl -fsSL -A 'CI-Sitemap-Check' "$SITEMAP" || true)"
            if [ -z "$map" ]; then
              echo "Sitemap not reachable yet."
            else
              missing=0
              while read -r url; do
                [ -z "${url:-}" ] && continue
                echo "  Checking: $url"
                echo "$map" | grep -F "$url" >/dev/null || missing=$((missing+1))
              done < "$urls_file"

              if [ $missing -eq 0 ]; then
                echo "All new URLs found in sitemap ✅"
                ok=1
                break
              else
                echo "$missing URL(s) not yet in sitemap."
              fi
            fi
            
            # Progressive backoff: longer waits as attempts increase
            if [ $tries -le 4 ]; then
              echo "Waiting 60 seconds before next attempt..."
              sleep 60
            elif [ $tries -le 8 ]; then
              echo "Waiting 90 seconds before next attempt..."
              sleep 90
            else
              echo "Waiting 120 seconds before next attempt..."
              sleep 120
            fi
          done

          if [ $ok -ne 1 ]; then
            echo "Sitemap did not include all new URLs within the wait window."
            echo "This might be a Cloudflare Pages caching issue or build delay."
            echo "The posts were committed successfully - they should appear shortly."
            
            # Optional: Make this a warning instead of failure
            # Uncomment the next line to make deployment succeed even if sitemap check fails
            # echo "⚠️  Continuing despite sitemap check failure"
            
            exit 1
          fi
